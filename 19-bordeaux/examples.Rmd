---
title: "Bordeaux 2019: examples"
author: "Guillaume A. Rousselet"
date: "`r Sys.Date()`"
output:
  github_document:
    html_preview: yes
    toc: yes
    toc_depth: 2
  # pdf_document:
  #   fig_caption: no
  #   number_sections: no
  #   toc: yes
  #   toc_depth: 2
---

```{r message=FALSE, warning=FALSE}
# dependencies
library(pwr)
library(ggplot2)
library(tibble)
library(retimes)
source("./functions.txt")
```

```{r}
sessionInfo()
```

# Power simulation 1

We assume a certain difference and sd for one-sample effect.

## Formula solution
```{r}
diff <- 1
sd <- 2
res <- pwr.t.test(d = abs(diff)/sd, sig.level = 0.05, power = .80, type = "one.sample")
```

To achieve a power of 80%, we need about `r ceiling(res[[1]])` participants (rounded up).

## Simulation check
```{r}
set.seed(21)
# a <- rnorm(20)
# comp.pval(a)
# t.test(a)

nsim <- 10000
n <- 34
mu <- 1
sd <- 2
alpha <- 0.05
mean(apply(matrix(rnorm(nsim * n, mean = mu, sd = sd), nrow = nsim), 1, comp.pval) <= alpha)
```

## Power curve

### Simulation
```{r}
nseq <- seq(5,100,5)
pres <- vector(mode = "numeric", length = length(nseq))
for(iter in 1:length(nseq)){
  pres[iter] <- mean(apply(matrix(rnorm(nsim * nseq[iter], mean = mu, sd = sd), nrow = nsim), 1, comp.pval) <= alpha)
}
```

### Illustrate results
```{r}
df <- tibble(Participants = nseq, 
             Power = pres)

ggplot(df, aes(x = Participants, y = Power)) + theme_classic() +
  geom_line(size = 1.5) +
  geom_abline(slope = 0, intercept = 0.80) +
  geom_abline(slope = 0, intercept = 0.90) +
  theme(axis.title.x = element_text(size = 18),
    axis.text = element_text(size = 16, colour = "black"), axis.title.y = element_text(size = 18),
    legend.text = element_text(size = 16),
    legend.title = element_text(size = 18)) +
  scale_x_continuous(breaks = seq(10, 100, 10)) + 
  scale_y_continuous(breaks = seq(0, 1, .1))
```

Using the approximation technique, we find that to achieve a power of 80%, we need about `r ceiling(approx(pres, nseq, 0.80)$y)` participants (rounded up).
Unsurprisingly we find the same value as in the previous calculation, but it's a good sanity check.

## Replication crisis?

Greenland et al. 2016:
"Despite its shortcomings for interpreting current data, power can be useful for designing studies and for understanding why replication of “statistical significance” will often fail even under ideal conditions. Studies are often designed or claimed to have 80% power against a key alternative when using a 0.05 signifi- cance level, although in execution often have less power due to unanticipated problems such as low subject recruitment. Thus, if the alternative is correct and the actual power of two studies is 80%, the chance that the studies will both show P ≤ 0.05 will at best be only 0.80(0.80) = 64%; furthermore, the chance that one study shows P ≤ 0.05 and the other does not (and thus will be misinterpreted as showing conflicting results) is 2(0.80)0.20 = 32% or about 1 chance in 3. Similar calculations taking account of typical problems suggest that one could antic- ipate a “replication crisis” even if there were no publication or reporting bias, simply because current design and testing con- ventions treat individual study results as dichotomous outputs of “significant”/“nonsignificant” or “reject”/“accept.”"

So, for 90% power, the chance that the studies will both show P ≤ 0.05 will at best be only 0.90(0.90) = 81%

## Simulation
```{r}
set.seed(777)

nsim <- 50000

# experiment 1
pval1 <- apply(matrix(rnorm(nsim * n, mean = mu, sd = sd), nrow = nsim), 1, comp.pval) <= alpha

# experiment 2
pval2 <- apply(matrix(rnorm(nsim * n, mean = mu, sd = sd), nrow = nsim), 1, comp.pval) <= alpha
```

Based on our simulation, if the alternative is correct and the actual power of two studies is 80%, the chance that the studies will both show P ≤ 0.05 will at best be `r  mean((pval1 + pval2)==2)`.

The chance that one study shows P ≤ 0.05 and the other does not is `r  mean((pval1 + pval2)==1)`

# Power simulation 2

## Generate population

We use ex-Gaussian parameters from the FLP dataset to generate realistic level 1 reaction time differences in a lexical decision task. For details see:
https://psyarxiv.com/3y54r/

```{r}
set.seed(1)
pop.size <- 100000 # number of participants
load('./flp_exg_param_interp.RData')
Np.total <- nrow(exg_param_interp)
nt <- 100 # trials per condition

pop <- vector(mode = "numeric", length = pop.size)
idvec <- sample(Np.total, pop.size, replace = TRUE) # vector of random id
for(P in 1:pop.size){
  # simulate data for the two conditions using nt trials
  w <- rexgauss(nt, 
    mu = exg_param_interp[idvec[P],1,1], 
    sigma = exg_param_interp[idvec[P],2,1], 
    tau = exg_param_interp[idvec[P],3,1])
  nw <- rexgauss(nt, 
    mu = exg_param_interp[idvec[P],1,2], 
    sigma = exg_param_interp[idvec[P],2,2], 
    tau = exg_param_interp[idvec[P],3,2])
  pop[P] <- mean(nw) - mean(w)
}

mean(pop) 
median(pop) 
sd(pop)
mean(pop) / sd(pop)
skew(pop)
```

### Illustrate level 1 population
```{r}
hist(pop, 50)
```

## Pilot experiment
```{r}
set.seed(23)
n <- 10
pilot.res <- sample(pop, n, replace = TRUE)
mean(pilot.res)
sd(pilot.res)
mean(pilot.res) / sd(pilot.res)
```

## Formula solution
```{r}
pilot.diff <- mean(pilot.res)
pilot.sd <- sd(pilot.res)
res <- pwr.t.test(d = abs(pilot.diff)/pilot.sd, sig.level = 0.05, power = .80, type = "one.sample")
```

To achieve a power of 80%, we need about `r ceiling(res[[1]])` participants (rounded up).

## Simulation check
```{r}
set.seed(21)

# check p values are correct:
# a <- rnorm(20)
# comp.pval(a)
# t.test(a)

# Use 10,000 iterations to estimate power - result is a bit larger than 80% because sample size is rounded up:
nsim <- 10000
n <- ceiling(res[[1]])
alpha <- 0.05
mean(apply(matrix(rnorm(nsim * n, mean = pilot.diff, sd = pilot.sd), nrow = nsim), 1, comp.pval) <= alpha)
```

## Power curve assuming normal distribution

### Simulation
```{r}
nseq <- seq(5,30,1)
pres <- vector(mode = "numeric", length = length(nseq))
for(iter in 1:length(nseq)){
  pres[iter] <- mean(apply(matrix(rnorm(nsim * nseq[iter], mean = pilot.diff, sd = pilot.sd), nrow = nsim), 1, comp.pval) <= alpha)
}
```

### Illustrate results
```{r}
df <- tibble(Participants = nseq, 
             Power = pres)

ggplot(df, aes(x = Participants, y = Power)) + theme_classic() +
  geom_line(size = 1.5) +
  geom_abline(slope = 0, intercept = 0.80) +
  geom_abline(slope = 0, intercept = 0.90) +
  theme(axis.title.x = element_text(size = 18),
    axis.text = element_text(size = 16, colour = "black"), axis.title.y = element_text(size = 18),
    legend.text = element_text(size = 16),
    legend.title = element_text(size = 18)) +
  scale_x_continuous(breaks = seq(5, 30, 5)) + 
  scale_y_continuous(breaks = seq(0, 1, .1))
```

Using the approximation technique, we find that to achieve a power of 80%, we need about `r ceiling(approx(pres, nseq, 0.80)$y)` participants (rounded up).
Unsurprisingly we find the same value as in the previous calculation, but it's a good sanity check.

## Power curve based on simulated population

### Simulation
```{r}
nseq <- seq(10,200,10)
pres <- vector(mode = "numeric", length = length(nseq))
for(iter in 1:length(nseq)){
  pres[iter] <- mean(apply(matrix(sample(pop, nsim * nseq[iter], replace = TRUE), nrow = nsim), 1, comp.pval) <= alpha)
}
```

### Illustrate sampling distribution for n = 10
```{r}
hist(apply(matrix(sample(pop, nsim * 10, replace = TRUE), nrow = nsim), 1, mean), 
      50,
      xlab = "Differences",
      main = "Sampling distribution for n = 10")
```

### Illustrate sampling distribution for n = 100
```{r}
hist(apply(matrix(sample(pop, nsim * 100, replace = TRUE), nrow = nsim), 1, mean), 
      50,
      xlab = "Differences",
      main = "Sampling distribution for n = 100")
```

### Illustrate results
```{r}
df <- tibble(Participants = nseq, 
             Power = pres)

ggplot(df, aes(x = Participants, y = Power)) + theme_classic() +
  geom_line(size = 1.5) +
  geom_abline(slope = 0, intercept = 0.80) +
  geom_abline(slope = 0, intercept = 0.90) +
  theme(axis.title.x = element_text(size = 18),
    axis.text = element_text(size = 12, colour = "black"), axis.title.y = element_text(size = 18),
    legend.text = element_text(size = 16),
    legend.title = element_text(size = 18)) +
  scale_x_continuous(breaks = seq(10, 200, 10)) + 
  scale_y_continuous(breaks = seq(0, 1, .1))
```

Using the approximation technique, we find that to achieve a power of 80%, we need about `r ceiling(approx(pres, nseq, 0.80)$y)` participants (rounded up).

Using the pilot study, we set n = `r ceiling(res[[1]])`, achieving a power of `r round(approx(nseq, pres, res[[1]])$y, digits = 2)`.

## Replication crisis?

### Simulation
```{r}
set.seed(777)

nsim <- 50000
n <- ceiling(approx(pres, nseq, 0.80)$y)

# experiment 1
pval1 <- apply(matrix(sample(pop, nsim * n, replace = TRUE), nrow = nsim), 1, comp.pval) <= alpha

# experiment 2
pval2 <- apply(matrix(sample(pop, nsim * n, replace = TRUE), nrow = nsim), 1, comp.pval) <= alpha
```

Based on our simulation, if the alternative is correct and the actual power of two studies is 80%, the chance that the studies will both show P ≤ 0.05 will at best be `r  mean((pval1 + pval2)==2)`.

The chance that one study shows P ≤ 0.05 and the other does not is `r  mean((pval1 + pval2)==1)`

## Estimation precision

### Generate data
```{r eval=FALSE}
set.seed(666)

preseq <- c(seq(5, 20, 5)) # precision bounds
Npre <- length(preseq)
ptseq <- seq(10, 150 ,10) # number of participants
Npt <- length(ptseq)
Nsim <- 10000

pop.diff.m <- mean(pop)
pop.diff.md <- median(pop)

# declare result matrices
res.pre.m <- matrix(data = 0, nrow = Npre, ncol = Npt)
res.pre.md <- matrix(data = 0, nrow = Npre, ncol = Npt)

for(iter.pt in 1:Npt){ # number of participants
 
  # print(paste0("Sample size ",iter.pt," out of ",Npt,"..."))
    
  mc.samp <- matrix(sample(pop, ptseq[iter.pt] * Nsim, replace = TRUE), nrow = Nsim)
    diff.m <- apply(mc.samp, 1, mean)
    diff.md <- apply(mc.samp, 1, median)
  
  # Probability of getting group estimate at most x ms from population value
  for(iter.p in 1:Npre){
    res.pre.m[iter.p, iter.pt] <- mean( abs(diff.m - pop.diff.m) <= (preseq[iter.p]) )
    res.pre.md[iter.p, iter.pt] <- mean( abs(diff.md - pop.diff.md) <= (preseq[iter.p]) )
  }

} # number of participants
```

### Precision results: mean
```{r}
df <- tibble(`Proportion` = as.vector(res.pre.m),
             `Precision` = rep(preseq, Npt),
             `N` = rep(ptseq, each = Npre))

df$Precision <- as.character(df$Precision)
df$Precision <- factor(df$Precision, levels=unique(df$Precision))

# make plot
p <- ggplot(df, aes(x=N, y=Proportion)) + theme_classic() +
   geom_line(aes(colour = Precision), size = 1) + 
  scale_color_viridis_d() +
  scale_x_continuous(breaks=ptseq) + 
  scale_y_continuous(breaks=seq(0, 1, 0.1)) +
  coord_cartesian(ylim=c(0, 1)) +
  theme(plot.title = element_text(size=20),
        axis.title.x = element_text(size = 18),
        axis.text = element_text(size = 14, colour="black"),
        axis.title.y = element_text(size = 18),
        legend.key.width = unit(1.5,"cm"),
        legend.position = c(0.8, 0.3),
        legend.text=element_text(size = 16),
        legend.title=element_text(size = 18),
        panel.background = element_rect(fill="grey90")) +
  labs(x = "Number of participants", y = "Proportion of estimates") +
  guides(colour = guide_legend(override.aes = list(size=3), # make thicker legend lines
    title = "Precision \n(within +/- ms)")) + # change legend title
  ggtitle("Measurement precision: mean") 
p
```

With n = `r ceiling(approx(pres, nseq, 0.80)$y)`, the group estimate will be, in the long run, within 5 ms of the true mean in `r 100*(approx(y=res.pre.m[1,],x=ptseq,xout=ceiling(approx(pres, nseq, 0.80)$y))$y)` % of experiments.

# Correlation sampling distribution

## Generate data
```{r}

```

## Plot results
```{r}

```

## Condition on P <= 0.05
```{r}

```

# References
Greenland, S., Senn, S.J., Rothman, K.J., Carlin, J.B., Poole, C., Goodman, S.N. & Altman, D.G. (2016) Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations. Eur J Epidemiol, 31, 337-350.

